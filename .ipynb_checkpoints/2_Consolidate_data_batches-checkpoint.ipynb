{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4042ca81",
   "metadata": {},
   "source": [
    "# Consolidate data (BATCH SPLIT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fcd801e",
   "metadata": {},
   "source": [
    "<div style=\"text-align: right\"> Author: Vassil Dimitrov </div>\n",
    "<div style=\"text-align: right\"> Date: 2023-08-01 </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d995fd78",
   "metadata": {},
   "source": [
    "As indicated in **2_Consolidate_data_1** the data will be split into batches and then the batches from all available tables except `encounters` will be merged in a single consolidated batch dataframe with encounters and corresponding values for each patient arranged by the time of occurrence."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b4f26f6",
   "metadata": {},
   "source": [
    "## Prep"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfab8b68",
   "metadata": {},
   "source": [
    "### Load libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "011b4e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44dd54e8",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b40d3abf",
   "metadata": {},
   "source": [
    "### `PATIENT` to index & explode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "acee0f06",
   "metadata": {},
   "outputs": [],
   "source": [
    "def patient_index_explode(tab):\n",
    "    # Create a new column 'encounter' to differentiate between duplicate rows for each patient\n",
    "    tab['encounter_n'] = tab.groupby('PATIENT').cumcount()+1\n",
    "    tab = tab.pivot_table(index='PATIENT',\n",
    "                          columns='encounter_n',\n",
    "                          aggfunc='first')\n",
    "    # Flatten the MultiIndex columns\n",
    "    tab.columns = [f'{col[0]}_{col[1]}' for col in tab.columns]\n",
    "    # Fill in nulls with 0\n",
    "    tab.fillna(0, inplace=True)\n",
    "    # Convert to uint32\n",
    "    tab=tab.astype('uint32')\n",
    "    sparse_dtype = pd.SparseDtype(np.uint32, fill_value=0)\n",
    "    tab = tab.astype(sparse_dtype)\n",
    "    return tab"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ced9c13c",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5946f2f",
   "metadata": {},
   "source": [
    "### Read & Tidy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ef434af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_n_tidy (tab_name_pkl):\n",
    "    tab = pd.read_pickle(tab_name_pkl)\n",
    "    tab.drop_duplicates (inplace=True)\n",
    "    tab.fillna(0, inplace=True)\n",
    "    cols2trans = list(tab.columns)\n",
    "    for col in cols2trans:\n",
    "        print(col)\n",
    "        if col == 'PATIENT':\n",
    "            continue\n",
    "        else:\n",
    "            tab[col] = tab[col].sparse.to_dense().astype(np.uint32)\n",
    "    return tab"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "042a91c3",
   "metadata": {},
   "source": [
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8869602a",
   "metadata": {},
   "source": [
    "## Split `patients` to batches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58a65fed",
   "metadata": {},
   "source": [
    "### Read in `patients` table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0f51fa02",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patients dimensions: (1192923, 29)\n"
     ]
    }
   ],
   "source": [
    "patients = pd.read_pickle('patients2.pkl')\n",
    "# Sanity check:\n",
    "print('Patients dimensions:', patients.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8b5c7b91",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MARITAL</th>\n",
       "      <th>GENDER</th>\n",
       "      <th>m_since_birth</th>\n",
       "      <th>RACE_asian</th>\n",
       "      <th>RACE_black</th>\n",
       "      <th>RACE_hispanic</th>\n",
       "      <th>RACE_native</th>\n",
       "      <th>RACE_white</th>\n",
       "      <th>ETHNICITY_african</th>\n",
       "      <th>ETHNICITY_american</th>\n",
       "      <th>...</th>\n",
       "      <th>ETHNICITY_irish</th>\n",
       "      <th>ETHNICITY_italian</th>\n",
       "      <th>ETHNICITY_mexican</th>\n",
       "      <th>ETHNICITY_polish</th>\n",
       "      <th>ETHNICITY_portuguese</th>\n",
       "      <th>ETHNICITY_puerto_rican</th>\n",
       "      <th>ETHNICITY_russian</th>\n",
       "      <th>ETHNICITY_scottish</th>\n",
       "      <th>ETHNICITY_swedish</th>\n",
       "      <th>ETHNICITY_west_indian</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PATIENT</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>d3ae0579-ac2c-48b0-a0c1-a858b63e3b99</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6304009d-9c80-44f0-ae72-4c42eb5e8f38</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>134</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>927cdcb7-adfb-4968-b5d4-745764eb931e</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>254</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47c8c88a-7c03-48d8-85d1-3f37299cac61</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>304</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>971c0a8b-e356-48d1-8de5-e0f9688b10cf</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>395</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      MARITAL  GENDER  m_since_birth  \\\n",
       "PATIENT                                                                \n",
       "d3ae0579-ac2c-48b0-a0c1-a858b63e3b99        0       0             50   \n",
       "6304009d-9c80-44f0-ae72-4c42eb5e8f38        0       0            134   \n",
       "927cdcb7-adfb-4968-b5d4-745764eb931e        0       1            254   \n",
       "47c8c88a-7c03-48d8-85d1-3f37299cac61        0       1            304   \n",
       "971c0a8b-e356-48d1-8de5-e0f9688b10cf        1       0            395   \n",
       "\n",
       "                                      RACE_asian  RACE_black  RACE_hispanic  \\\n",
       "PATIENT                                                                       \n",
       "d3ae0579-ac2c-48b0-a0c1-a858b63e3b99           0           0              0   \n",
       "6304009d-9c80-44f0-ae72-4c42eb5e8f38           0           0              0   \n",
       "927cdcb7-adfb-4968-b5d4-745764eb931e           0           0              0   \n",
       "47c8c88a-7c03-48d8-85d1-3f37299cac61           0           0              0   \n",
       "971c0a8b-e356-48d1-8de5-e0f9688b10cf           0           0              0   \n",
       "\n",
       "                                      RACE_native  RACE_white  \\\n",
       "PATIENT                                                         \n",
       "d3ae0579-ac2c-48b0-a0c1-a858b63e3b99            0           1   \n",
       "6304009d-9c80-44f0-ae72-4c42eb5e8f38            0           1   \n",
       "927cdcb7-adfb-4968-b5d4-745764eb931e            0           1   \n",
       "47c8c88a-7c03-48d8-85d1-3f37299cac61            0           1   \n",
       "971c0a8b-e356-48d1-8de5-e0f9688b10cf            0           1   \n",
       "\n",
       "                                      ETHNICITY_african  ETHNICITY_american  \\\n",
       "PATIENT                                                                       \n",
       "d3ae0579-ac2c-48b0-a0c1-a858b63e3b99                  0                   0   \n",
       "6304009d-9c80-44f0-ae72-4c42eb5e8f38                  0                   0   \n",
       "927cdcb7-adfb-4968-b5d4-745764eb931e                  0                   0   \n",
       "47c8c88a-7c03-48d8-85d1-3f37299cac61                  0                   0   \n",
       "971c0a8b-e356-48d1-8de5-e0f9688b10cf                  0                   0   \n",
       "\n",
       "                                      ...  ETHNICITY_irish  ETHNICITY_italian  \\\n",
       "PATIENT                               ...                                       \n",
       "d3ae0579-ac2c-48b0-a0c1-a858b63e3b99  ...                0                  0   \n",
       "6304009d-9c80-44f0-ae72-4c42eb5e8f38  ...                0                  0   \n",
       "927cdcb7-adfb-4968-b5d4-745764eb931e  ...                1                  0   \n",
       "47c8c88a-7c03-48d8-85d1-3f37299cac61  ...                0                  0   \n",
       "971c0a8b-e356-48d1-8de5-e0f9688b10cf  ...                0                  0   \n",
       "\n",
       "                                      ETHNICITY_mexican  ETHNICITY_polish  \\\n",
       "PATIENT                                                                     \n",
       "d3ae0579-ac2c-48b0-a0c1-a858b63e3b99                  0                 0   \n",
       "6304009d-9c80-44f0-ae72-4c42eb5e8f38                  0                 0   \n",
       "927cdcb7-adfb-4968-b5d4-745764eb931e                  0                 0   \n",
       "47c8c88a-7c03-48d8-85d1-3f37299cac61                  0                 0   \n",
       "971c0a8b-e356-48d1-8de5-e0f9688b10cf                  0                 0   \n",
       "\n",
       "                                      ETHNICITY_portuguese  \\\n",
       "PATIENT                                                      \n",
       "d3ae0579-ac2c-48b0-a0c1-a858b63e3b99                     0   \n",
       "6304009d-9c80-44f0-ae72-4c42eb5e8f38                     0   \n",
       "927cdcb7-adfb-4968-b5d4-745764eb931e                     0   \n",
       "47c8c88a-7c03-48d8-85d1-3f37299cac61                     0   \n",
       "971c0a8b-e356-48d1-8de5-e0f9688b10cf                     0   \n",
       "\n",
       "                                      ETHNICITY_puerto_rican  \\\n",
       "PATIENT                                                        \n",
       "d3ae0579-ac2c-48b0-a0c1-a858b63e3b99                       0   \n",
       "6304009d-9c80-44f0-ae72-4c42eb5e8f38                       0   \n",
       "927cdcb7-adfb-4968-b5d4-745764eb931e                       0   \n",
       "47c8c88a-7c03-48d8-85d1-3f37299cac61                       0   \n",
       "971c0a8b-e356-48d1-8de5-e0f9688b10cf                       0   \n",
       "\n",
       "                                      ETHNICITY_russian  ETHNICITY_scottish  \\\n",
       "PATIENT                                                                       \n",
       "d3ae0579-ac2c-48b0-a0c1-a858b63e3b99                  0                   1   \n",
       "6304009d-9c80-44f0-ae72-4c42eb5e8f38                  0                   0   \n",
       "927cdcb7-adfb-4968-b5d4-745764eb931e                  0                   0   \n",
       "47c8c88a-7c03-48d8-85d1-3f37299cac61                  0                   0   \n",
       "971c0a8b-e356-48d1-8de5-e0f9688b10cf                  0                   0   \n",
       "\n",
       "                                      ETHNICITY_swedish  ETHNICITY_west_indian  \n",
       "PATIENT                                                                         \n",
       "d3ae0579-ac2c-48b0-a0c1-a858b63e3b99                  0                      0  \n",
       "6304009d-9c80-44f0-ae72-4c42eb5e8f38                  0                      0  \n",
       "927cdcb7-adfb-4968-b5d4-745764eb931e                  0                      0  \n",
       "47c8c88a-7c03-48d8-85d1-3f37299cac61                  0                      0  \n",
       "971c0a8b-e356-48d1-8de5-e0f9688b10cf                  0                      0  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(patients.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ae92eca",
   "metadata": {},
   "source": [
    "The table contains 1,192,923 entries (patients) with 29 features associated with each patient."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b268e579",
   "metadata": {},
   "source": [
    "### Split `patients` in batches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "958517a5",
   "metadata": {},
   "source": [
    "The `patients` table will be split into batches containing 120,000 entries (120,000) patients. Each batch will be used to train and optimize a RNN implying that it will be further split into a train-validation subsets. A meta-model will be constructed that takes as input the outputs of the independently trained RNNs for each batch. Overall, the process will follow the workflow below:\n",
    "1. batch1:\n",
    "    - RNN_1 (119,293)\n",
    "    - train\n",
    "    - validation (for optimization)\n",
    "2. batch2\n",
    "    - RNN_2 (119,293)\n",
    "    - train\n",
    "    - validation (for optimization)\n",
    "3. batch3\n",
    "    - RNN_3 (119,293)\n",
    "    - train\n",
    "    - validation (for optimization)\n",
    "4. batch4\n",
    "    - RNN_4 (119,293)\n",
    "    - train\n",
    "    - validation (for optimization)\n",
    "5. batch5\n",
    "    - RNN_5 (119,293)\n",
    "    - train\n",
    "    - validation (for optimization)\n",
    "6. batch6\n",
    "    - RNN_6 (119,293)\n",
    "    - train\n",
    "    - validation (for optimization)\n",
    "7. batch7\n",
    "    - RNN_7 (119,293)\n",
    "    - train\n",
    "    - validation (for optimization)\n",
    "8. batch8\n",
    "    - Meta model performance assessment (119,293)  \n",
    "9. batch9 & 10\n",
    "    - Meta model incorporating all RNN outputs\n",
    "    - train (batch 1-7)\n",
    "    - validation (238,579 for optimization)\n",
    "  \n",
    "  Essentially, every 10th patient will be put into the same batch so that each batch contains approximately 120,000 patients.\n",
    "  >**Important** to note that before the batches are obtained, the data will be shuffled twice in order to ensure no underlying patterns are captured when distributing it to batches for training. In any case, even if that were the case, the ensemble machine learning method adopted here will largely mitigate such effects.    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "099af93f",
   "metadata": {},
   "source": [
    "#### Reshuffle data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d813666c",
   "metadata": {},
   "source": [
    "The data will be randomly reshuffled thrice for randomness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c6d22e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshuffle 1\n",
    "patients = patients.sample(frac=1)\n",
    "# Reshuffle 2\n",
    "patients = patients.sample(frac=1)\n",
    "# Reshuffle 3\n",
    "patients = patients.sample(frac=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6c29122",
   "metadata": {},
   "source": [
    "#### Split data into batches and save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6f2c67b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total entries -- 1192923\n",
      "number of batches -- 10\n",
      "batch_size -- 119293\n"
     ]
    }
   ],
   "source": [
    "# Calculate the total number of rows in the DataFrame\n",
    "total_rows = len(patients)\n",
    "print('total entries --', total_rows)\n",
    "\n",
    "# Number of batches = 10\n",
    "num_batches = 10\n",
    "print('number of batches --', num_batches)\n",
    "\n",
    "# Determine the batch size (every 10th row)\n",
    "batch_size = math.ceil(total_rows / num_batches)\n",
    "print('batch_size --', batch_size)\n",
    "\n",
    "# Create an empty list to store the batches\n",
    "batches = []\n",
    "\n",
    "# Loop through the DataFrame and create batches\n",
    "for i in range(num_batches):\n",
    "    start_idx = i * batch_size\n",
    "    end_idx = start_idx + batch_size\n",
    "    batch = patients.iloc[start_idx:end_idx]\n",
    "    batches.append(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b7049f87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(119293, 29)\n",
      "(119293, 29)\n",
      "(119293, 29)\n",
      "(119293, 29)\n",
      "(119293, 29)\n",
      "(119293, 29)\n",
      "(119293, 29)\n",
      "(119293, 29)\n",
      "(119293, 29)\n",
      "(119286, 29)\n"
     ]
    }
   ],
   "source": [
    "# Sanity check:\n",
    "for i in batches:\n",
    "    print(i.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "129dae65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sanity check 2:\n",
    "list(batches[0].index) in list(batches[1].index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cc437c0",
   "metadata": {},
   "source": [
    "Now extract each dataframe from batch, save it as a separate object and as a pickle file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "84ce5256",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished extracting patients_batch1...\n",
      "Finished saving patients_batch1.\n",
      "Finished extracting patients_batch2...\n",
      "Finished saving patients_batch2.\n",
      "Finished extracting patients_batch3...\n",
      "Finished saving patients_batch3.\n",
      "Finished extracting patients_batch4...\n",
      "Finished saving patients_batch4.\n",
      "Finished extracting patients_batch5...\n",
      "Finished saving patients_batch5.\n",
      "Finished extracting patients_batch6...\n",
      "Finished saving patients_batch6.\n",
      "Finished extracting patients_batch7...\n",
      "Finished saving patients_batch7.\n",
      "Finished extracting patients_batch8...\n",
      "Finished saving patients_batch8.\n",
      "Finished extracting patients_batch9...\n",
      "Finished saving patients_batch9.\n",
      "Finished extracting patients_batch10...\n",
      "Finished saving patients_batch10.\n"
     ]
    }
   ],
   "source": [
    "for i, df in enumerate(batches):\n",
    "    df_name = f'patients_batch{i+1}'\n",
    "    exec(f'{df_name} = df')\n",
    "    print(f'Finished extracting {df_name}...')\n",
    "    exec(f'{df_name}.to_pickle(\"{df_name}.pkl\")')\n",
    "    print(f'Finished saving {df_name}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcd468e2",
   "metadata": {},
   "source": [
    "At this point, each batch will be processed separately in order to consolidate all available data into a dataframe amenable to RNN modeling."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe4130fe",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
